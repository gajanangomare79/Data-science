{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1hDk9hDvOH7",
    "outputId": "d74d5480-9c95-47e1-f558-fd43d2251366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n",
      "/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "#Change current working directory to gdrive\n",
    "%cd /gdrive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_k0z66e38lG",
    "outputId": "2df480a6-b34b-4071-8a90-148c37fbcdcb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "#NLTK-------------------------------\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.stemporter import PorterStemmer\n",
    "\n",
    "# Import libraries for feature \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMwGQK7KAd7T",
    "outputId": "6ec885de-3659-46e1-f8d7-499d776b03a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 2)\n",
      "(2070, 17)\n"
     ]
    }
   ],
   "source": [
    "#Read files\n",
    "textfile = r'/gdrive/My Drive/CIS508-FALL2020/PT5A/Comments.csv'\n",
    "textData = pd.read_csv(textfile) #creates a dataframe\n",
    "\n",
    "CustInfofile = r'/gdrive/My Drive/CIS508-FALL2020/PT5A/Customers.csv'\n",
    "CustInfoData = pd.read_csv(CustInfofile)  #creates a dataframe\n",
    "\n",
    "print(textData.shape)\n",
    "print(CustInfoData.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWOTk6C1Ao45",
    "outputId": "229f3b49-904e-47c4-a327-40c33a17006c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 16)\n",
      "   ID Sex Status  Children  Est_Income Car_Owner   Usage        Age  RatePlan  \\\n",
      "0   1   F      S         1    38000.00         N  229.64  24.393333         3   \n",
      "1   6   M      M         2    29616.00         N   75.29  49.426667         2   \n",
      "2   8   M      M         0    19732.80         N   47.25  50.673333         3   \n",
      "3  11   M      S         2       96.33         N   59.01  56.473333         1   \n",
      "4  14   F      M         2    52004.80         N   28.14  25.140000         1   \n",
      "\n",
      "   LongDistance  International   Local  Dropped Paymethod LocalBilltype  \\\n",
      "0         23.56            0.0  206.08        0        CC        Budget   \n",
      "1         29.78            0.0   45.50        0        CH     FreeLocal   \n",
      "2         24.81            0.0   22.44        0        CC     FreeLocal   \n",
      "3         26.13            0.0   32.88        1        CC        Budget   \n",
      "4          5.03            0.0   23.11        0        CH        Budget   \n",
      "\n",
      "  LongDistanceBilltype  \n",
      "0       Intnl_discount  \n",
      "1             Standard  \n",
      "2             Standard  \n",
      "3             Standard  \n",
      "4       Intnl_discount  \n",
      "(2070, 2)\n",
      "     ID                                           Comments\n",
      "0  1309  Does not like the way the phone works. It is t...\n",
      "1  3556  Wanted to know the nearest store location. Wan...\n",
      "2  2230  Wants to know how to do text messaging. Referr...\n",
      "3  2312  Asked how to disable call waiting. referred hi...\n",
      "4  3327  Needs help learning how to use the phone. I su...\n",
      "0       Cancelled\n",
      "1         Current\n",
      "2         Current\n",
      "3         Current\n",
      "4       Cancelled\n",
      "          ...    \n",
      "2065    Cancelled\n",
      "2066    Cancelled\n",
      "2067    Cancelled\n",
      "2068    Cancelled\n",
      "2069    Cancelled\n",
      "Name: TARGET, Length: 2070, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Extract target column from Customer Info file\n",
    "y_train = CustInfoData[\"TARGET\"]\n",
    "X_train = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n",
    "                     \n",
    "print(X_train.shape)\n",
    "print(X_train.head())\n",
    "print(textData.shape)\n",
    "print(textData.head())\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cuWYNz2Ep17l"
   },
   "outputs": [],
   "source": [
    "#Tokenize - Split the sentences to lists of words\n",
    "textData['CommentsTokenized'] = textData['Comments'].apply(word_tokenize)\n",
    "\n",
    "export_csv = textData.to_csv(r'/gdrive/My Drive/CIS508-FALL2020/PT5A/TextDataTokenized1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XeYXLU-u_v9R"
   },
   "outputs": [],
   "source": [
    "# Use English stemmer.\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "#Now do stemming - create a new dataframe to store stemmed version\n",
    "newTextData=pd.DataFrame()\n",
    "newTextData=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
    "newTextData['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
    "\n",
    "export_csv = newTextData.to_csv(r'/gdrive/My Drive/CIS508-FALL2020/PT5A/newTextDataTS.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "M07E7VW7_y0d"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Join stemmed strings\n",
    "newTextData['CommentsTokenizedStemmed'] = newTextData['CommentsTokenizedStemmed'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "export_csv = newTextData.to_csv(r'/gdrive/My Drive/CIS508-FALL2020/PT5A/newTextData-Joined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WiBguQloljam",
    "outputId": "5c04898b-c209-4050-bc5f-a2746d075066"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 354)\n",
      "int64\n",
      "['3399', '3g', 'abysm', 'access', 'accessori', 'adapt', 'add', 'addit', 'additon', 'address', 'adit', 'adress', 'advertis', 'afraid', 'alway', 'angel', 'angri', 'ani', 'anoth', 'anyth', 'anytim', 'area', 'asap', 'ask', 'bad', 'basic', 'bateri', 'batteri', 'becaus', 'believ', 'better', 'bigger', 'book', 'bought', 'brain', 'bring', 'built', 'busi', 'button', 'buy', 'cancel', 'cancer', 'car', 'care', 'carrier', 'caus', 'cc', 'cell', 'certain', 'chang', 'charg', 'charger', 'check', 'chip', 'citi', 'claim', 'cleariti', 'cold', 'comapr', 'compani', 'compar', 'competit', 'complain', 'complaint', 'concept', 'connect', 'consisit', 'consist', 'constan', 'contact', 'continu', 'contract', 'correct', 'cost', 'coupl', 'cover', 'coverag', 'creat', 'credit', 'cstmer', 'cstmr', 'current', 'cust', 'custom', 'customr', 'date', 'day', 'dead', 'decent', 'defect', 'deo', 'did', 'die', 'differ', 'difficult', 'digiti', 'direct', 'disabl', 'doe', 'don', 'dont', 'drop', 'dure', 'easier', 'effect', 'encount', 'end', 'enemi', 'equip', 'everytim', 'everywher', 'evrey', 'exact', 'expect', 'expir', 'explain', 'facepl', 'fals', 'famili', 'featur', 'fed', 'figur', 'fine', 'fix', 'forev', 'forward', 'friend', 'function', 'furthermor', 'futur', 'gave', 'goat', 'good', 'great', 'gsm', 'handset', 'happi', 'hard', 'hate', 'hear', 'heard', 'help', 'higher', 'highway', 'hochi', 'hole', 'home', 'hope', 'horribl', 'hous', 'implement', 'improv', 'inadequ', 'includ', 'info', 'inform', 'ing', 'internet', 'intersect', 'issu', 'june', 'just', 'kid', 'kno', 'know', 'lame', 'later', 'lctn', 'learn', 'leroy', 'like', 'line', 'list', 'local', 'locat', 'locatn', 'long', 'los', 'lost', 'lot', 'love', 'major', 'make', 'manag', 'mani', 'manual', 'market', 'mean', 'messag', 'metropolitian', 'minut', 'misl', 'mistak', 'model', 'momma', 'mr', 'napeleon', 'near', 'nearest', 'need', 'network', 'new', 'news', 'notic', 'number', 'numer', 'offer', 'old', 'om', 'open', 'option', 'ori', 'ot', 'outbound', 'pass', 'pay', 'pda', 'peopl', 'perform', 'person', 'phone', 'piec', 'plan', 'pleas', 'point', 'polici', 'poor', 'possibl', 'probabl', 'problem', 'proper', 'provid', 'provis', 'purpos', 'rate', 'rater', 'realiz', 'realli', 'reason', 'receiv', 'recept', 'recption', 'reenter', 'refer', 'relat', 'rep', 'replac', 'respect', 'result', 'rid', 'right', 'ring', 'roam', 'roll', 'rubbish', 'rude', 'said', 'sale', 'say', 'screen', 'self', 'send', 'servic', 'shitti', 'shut', 'sign', 'signal', 'signific', 'simm', 'simpli', 'sinc', 'site', 'slow', 'sold', 'someon', 'sometim', 'soon', 'speak', 'speed', 'start', 'static', 'stole', 'store', 'stuff', 'stupid', 'substant', 'subtract', 'suck', 'suggest', 'supervisor', 'support', 'sure', 'surpris', 'suspect', 'suspend', 'switch', 'teach', 'technic', 'tell', 'terribl', 'test', 'text', 'think', 'thought', 'ticket', 'till', 'time', 'tire', 'today', 'toilet', 'told', 'tone', 'tower', 'transeff', 'transf', 'transfer', 'travel', 'tri', 'trust', 'turn', 'uncomfort', 'understand', 'unhappi', 'unlimit', 'unreli', 'unwil', 'upset', 'usag', 'use', 'useless', 'valu', 'veri', 'vm', 'wa', 'wait', 'want', 'wast', 'way', 'weak', 'web', 'websit', 'week', 'whi', 'wife', 'wish', 'wll', 'wold', 'work', 'wors', 'worst', 'wrong', 'xvyx', 'year', 'york']\n",
      "      0    1    2    3    4    5    6    7    8    9    ...  344  345  346  \\\n",
      "0       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "1       0    0    0    0    1    0    0    0    0    0  ...    0    0    0   \n",
      "2       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "3       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "4       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "2065    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "2066    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "2067    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "2068    0    0    0    0    0    0    0    0    0    1  ...    0    0    0   \n",
      "2069    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "\n",
      "      347  348  349  350  351  352  353  \n",
      "0       1    0    0    0    0    0    0  \n",
      "1       0    0    0    0    0    0    0  \n",
      "2       0    0    0    0    0    0    0  \n",
      "3       0    0    0    0    0    0    0  \n",
      "4       0    0    0    0    0    0    0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  \n",
      "2065    0    0    0    0    0    0    0  \n",
      "2066    0    0    0    0    0    0    0  \n",
      "2067    0    0    0    0    0    0    0  \n",
      "2068    0    0    0    0    0    0    0  \n",
      "2069    0    0    0    0    0    0    0  \n",
      "\n",
      "[2070 rows x 354 columns]\n"
     ]
    }
   ],
   "source": [
    "#Do Bag-Of-Words model - Term - Document Matrix\n",
    "#Learn the vocabulary dictionary and return term-document matrix.\n",
    "#count_vect = CountVectorizer(stop_words=None)\n",
    "count_vect = CountVectorizer(stop_words='english',lowercase=False)\n",
    "TD_counts = count_vect.fit_transform(newTextData.CommentsTokenizedStemmed)\n",
    "print(TD_counts.shape)\n",
    "print(TD_counts.dtype)\n",
    "print(count_vect.get_feature_names())\n",
    "#print(TD_counts)\n",
    "DF_TD_Counts=pd.DataFrame(TD_counts.toarray())\n",
    "print(DF_TD_Counts)\n",
    "export_csv = DF_TD_Counts.to_csv(r'/gdrive/My Drive/CIS508-FALL2020/PT5A/TD_counts-TokenizedStemmed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pd8TZYnAxQbP",
    "outputId": "486eaf6d-a888-4573-a7d8-de0a31890fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 354)\n",
      "      0    1    2    3        4    5    6    7    8         9    ...  344  \\\n",
      "0     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "1     0.0  0.0  0.0  0.0  0.27568  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "2     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "3     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "4     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "...   ...  ...  ...  ...      ...  ...  ...  ...  ...       ...  ...  ...   \n",
      "2065  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "2066  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "2067  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "2068  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.772949  ...  0.0   \n",
      "2069  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "\n",
      "      345  346       347  348  349  350  351  352  353  \n",
      "0     0.0  0.0  0.209678  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...   ...  ...       ...  ...  ...  ...  ...  ...  ...  \n",
      "2065  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2066  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2067  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2068  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2069  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[2070 rows x 354 columns]\n"
     ]
    }
   ],
   "source": [
    "#Compute TF-IDF Matrix\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(TD_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "DF_TF_IDF=pd.DataFrame(X_train_tfidf.toarray())\n",
    "print(DF_TF_IDF)\n",
    "export_csv= DF_TF_IDF.to_csv(r'/gdrive/My Drive/CIS508-FALL2020/PT5A/TFIDF_counts-TokenizedStemmed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2owIUD6_eYO",
    "outputId": "91a3ae45-575b-4281-b2d8-8106b4df37e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 25)\n",
      "[ 14  49  50  51  62  70  81 115 118 121 186 190 212 217 222 235 239 248\n",
      " 249 259 273 307 313 319 342]\n",
      "       0         1         2    3    4    5    6         7    8         9   \\\n",
      "0     0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "1     0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "2     0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "3     0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "4     0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "...   ...       ...       ...  ...  ...  ...  ...       ...  ...       ...   \n",
      "2065  0.0  0.000000  0.446161  0.0  0.0  0.0  0.0  0.460113  0.0  0.457852   \n",
      "2066  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "2067  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "2068  0.0  0.545354  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "2069  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "\n",
      "      ...   15   16   17   18   19   20   21   22   23   24  \n",
      "0     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "2065  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2066  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2067  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2068  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2069  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[2070 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "#Feature selection\n",
    "#Suppose, we select 50 features with top 50 Fisher scores\n",
    "selector = SelectKBest(k=25)\n",
    "#selector = SelectKBest(score_func=chi2, k=25)\n",
    "\n",
    "#new_DF_TF_IDF = SelectKBest(score_func=chi2, k=50).fit_transform(DF_TF_IDF,y_train)\n",
    "new_DF_TF_IDF = selector.fit_transform(DF_TF_IDF,y_train)\n",
    "print(new_DF_TF_IDF.shape)\n",
    "\n",
    "feature_names_out = selector.get_support(indices=True)\n",
    "print(feature_names_out)\n",
    "\n",
    "DF_TF_IDF_SelectedFeatures= pd.DataFrame(new_DF_TF_IDF)\n",
    "print(DF_TF_IDF_SelectedFeatures)\n",
    "\n",
    "export_csv= DF_TF_IDF_SelectedFeatures.to_csv(r'/gdrive/My Drive/CIS508-FALL2020/PT5A/TFIDF_counts-Selected Features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "geVCLka8xxjf",
    "outputId": "62a7a5cf-9dc0-483e-b8b3-50012bad7376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.630435\n",
      "Confusion Matrix:\n",
      "[[  63  741]\n",
      " [  24 1242]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       0.72      0.08      0.14       804\n",
      "     Current       0.63      0.98      0.76      1266\n",
      "\n",
      "    accuracy                           0.63      2070\n",
      "   macro avg       0.68      0.53      0.45      2070\n",
      "weighted avg       0.66      0.63      0.52      2070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Construct a Random Forest Classifier on text data\n",
    "clf=RandomForestClassifier()\n",
    "RF_text = clf.fit(DF_TF_IDF_SelectedFeatures,y_train)\n",
    "print(\"Accuracy score (training): {0:.6f}\".format(clf.score(DF_TF_IDF_SelectedFeatures, y_train)))\n",
    "rf_predictions = clf.predict(DF_TF_IDF_SelectedFeatures)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, rf_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_train, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqbfLq71jxit",
    "outputId": "b2495308-72fd-4f75-8fbd-ead4c72e809a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== All Accuracy Scores ===\n",
      "[0.52864886 0.48896632 0.52071235 0.53290747 0.496875   0.5546875\n",
      " 0.51875    0.5234375  0.4890625  0.546875   0.54206349 0.52619048\n",
      " 0.49662698 0.525      0.49325397 0.49662698 0.5125     0.53075397\n",
      " 0.48075397 0.50119048]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - ON Text:  0.5152941407762291\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run cross-validation - Text Data\n",
    "clf_cv_score = cross_val_score(clf, DF_TF_IDF_SelectedFeatures, y_train, cv=20, scoring=\"balanced_accuracy\")\n",
    "print(\"=== All Accuracy Scores ===\")\n",
    "print(clf_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean Accuracy Score ===\")\n",
    "print(\"Mean Accuracy Score - ON Text: \",clf_cv_score.mean())\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x0t7zQf5-_WR",
    "outputId": "7db27ee1-b50a-4708-8879-44610cd68336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 370)\n"
     ]
    }
   ],
   "source": [
    "#merge files\n",
    "DF_TF_IDF['ID'] = textData['ID']\n",
    "combined = pd.merge(X_train, DF_TF_IDF, on ='ID')\n",
    "print(combined.shape)\n",
    "combined.head()\n",
    "export_csv= combined.to_csv(r'/gdrive/My Drive/CIS508-FALL2020/PT5A/Combined2-Cust+TFIDF+SelectedFeatures.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPmJYiWrPkRG",
    "outputId": "209a2bb8-2627-41cc-d5b4-eaeb9076b2bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex', 'Status', 'Car_Owner', 'Paymethod', 'LocalBilltype', 'LongDistanceBilltype']\n",
      "(2070, 378)\n"
     ]
    }
   ],
   "source": [
    "#Do one Hot encoding for categorical features\n",
    "X_cat = [\"Sex\",\"Status\",\"Car_Owner\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\"]\n",
    "#X_cat = combined.select_dtypes(exclude=['int','float64'])\n",
    "print(X_cat)\n",
    "combined_one_hot = pd.get_dummies(combined,columns=X_cat)\n",
    "print(combined_one_hot.shape)\n",
    "export_csv= combined_one_hot.to_csv(r'/gdrive/My Drive/CIS508-FALL2020/PT5A/combined_one_hot.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DEMpFKQAVuV1",
    "outputId": "752df229-466e-483b-b313-d513240587d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 1.000000\n",
      "Confusion Matrix:\n",
      "[[ 804    0]\n",
      " [   0 1266]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       1.00      1.00      1.00       804\n",
      "     Current       1.00      1.00      1.00      1266\n",
      "\n",
      "    accuracy                           1.00      2070\n",
      "   macro avg       1.00      1.00      1.00      2070\n",
      "weighted avg       1.00      1.00      1.00      2070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Construct a Random Forest Classifier on combined data\n",
    "#clf1=RandomForestClassifier()\n",
    "RF_Comb = clf.fit(combined_one_hot,y_train)\n",
    "print(\"Accuracy score (training): {0:.6f}\".format(clf.score(combined_one_hot, y_train)))\n",
    "rf_predictions = clf.predict(combined_one_hot)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, rf_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_train, rf_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3RDRxnDRkcxo",
    "outputId": "cbd86f8e-a41d-4192-a2a0-021a770db94e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== All Accuracy Scores ===\n",
      "[0.85598142 0.87185443 0.85849787 0.91153697 0.875      0.9015625\n",
      " 0.8390625  0.8140625  0.871875   0.878125   0.91369048 0.89781746\n",
      " 0.90575397 0.76051587 0.89781746 0.88531746 0.91031746 0.94662698\n",
      " 0.90238095 0.89781746]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - ON Text:  0.8797806874274098\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run cross-validation - COMBINED Data\n",
    "rf_Comb_cv_score = cross_val_score(RF_Comb, combined_one_hot, y_train, cv=20, scoring=\"balanced_accuracy\")\n",
    "print(\"=== All Accuracy Scores ===\")\n",
    "print(rf_Comb_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean Accuracy Score ===\")\n",
    "print(\"Mean Accuracy Score - ON Text: \",rf_Comb_cv_score.mean())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qf1MEHy8I1f6",
    "outputId": "55346df8-fc28-4e04-c909-a111ec3008b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 17)\n",
      "(2070, 9)\n",
      "   Children  Est_Income   Usage        Age  RatePlan  LongDistance  \\\n",
      "0         1    38000.00  229.64  24.393333         3         23.56   \n",
      "1         2    29616.00   75.29  49.426667         2         29.78   \n",
      "2         0    19732.80   47.25  50.673333         3         24.81   \n",
      "3         2       96.33   59.01  56.473333         1         26.13   \n",
      "4         2    52004.80   28.14  25.140000         1          5.03   \n",
      "\n",
      "   International   Local  Dropped  \n",
      "0            0.0  206.08        0  \n",
      "1            0.0   45.50        0  \n",
      "2            0.0   22.44        0  \n",
      "3            0.0   32.88        1  \n",
      "4            0.0   23.11        0  \n",
      "(2070, 343)\n",
      "    25   26   27   28   29   30   31   32   33   34  ...  Status_S  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         1   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         1   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0   \n",
      "\n",
      "   Car_Owner_N  Car_Owner_Y  Paymethod_Auto  Paymethod_CC  Paymethod_CH  \\\n",
      "0            1            0               0             1             0   \n",
      "1            1            0               0             0             1   \n",
      "2            1            0               0             1             0   \n",
      "3            1            0               0             1             0   \n",
      "4            1            0               0             0             1   \n",
      "\n",
      "   LocalBilltype_Budget  LocalBilltype_FreeLocal  \\\n",
      "0                     1                        0   \n",
      "1                     0                        1   \n",
      "2                     0                        1   \n",
      "3                     1                        0   \n",
      "4                     1                        0   \n",
      "\n",
      "   LongDistanceBilltype_Intnl_discount  LongDistanceBilltype_Standard  \n",
      "0                                    1                              0  \n",
      "1                                    0                              1  \n",
      "2                                    0                              1  \n",
      "3                                    0                              1  \n",
      "4                                    1                              0  \n",
      "\n",
      "[5 rows x 343 columns]\n",
      "(2070, 352)\n",
      "   Children  Est_Income   Usage        Age  RatePlan  LongDistance  \\\n",
      "0         1    38000.00  229.64  24.393333         3         23.56   \n",
      "1         2    29616.00   75.29  49.426667         2         29.78   \n",
      "2         0    19732.80   47.25  50.673333         3         24.81   \n",
      "3         2       96.33   59.01  56.473333         1         26.13   \n",
      "4         2    52004.80   28.14  25.140000         1          5.03   \n",
      "\n",
      "   International   Local  Dropped   25  ...  Status_S  Car_Owner_N  \\\n",
      "0            0.0  206.08        0  0.0  ...         1            1   \n",
      "1            0.0   45.50        0  0.0  ...         0            1   \n",
      "2            0.0   22.44        0  0.0  ...         0            1   \n",
      "3            0.0   32.88        1  0.0  ...         1            1   \n",
      "4            0.0   23.11        0  0.0  ...         0            1   \n",
      "\n",
      "   Car_Owner_Y  Paymethod_Auto  Paymethod_CC  Paymethod_CH  \\\n",
      "0            0               0             1             0   \n",
      "1            0               0             0             1   \n",
      "2            0               0             1             0   \n",
      "3            0               0             1             0   \n",
      "4            0               0             0             1   \n",
      "\n",
      "   LocalBilltype_Budget  LocalBilltype_FreeLocal  \\\n",
      "0                     1                        0   \n",
      "1                     0                        1   \n",
      "2                     0                        1   \n",
      "3                     1                        0   \n",
      "4                     1                        0   \n",
      "\n",
      "   LongDistanceBilltype_Intnl_discount  LongDistanceBilltype_Standard  \n",
      "0                                    1                              0  \n",
      "1                                    0                              1  \n",
      "2                                    0                              1  \n",
      "3                                    0                              1  \n",
      "4                                    1                              0  \n",
      "\n",
      "[5 rows x 352 columns]\n"
     ]
    }
   ],
   "source": [
    "#Construct a Random Forest Classifier WITHOUT text data\n",
    "print(CustInfoData.shape)\n",
    "X_train1=combined_one_hot.iloc[:,1:10]\n",
    "#X_train2=combined_one_hot.iloc[:,60:]\n",
    "X_train2=combined_one_hot.iloc[:,35:]\n",
    "print(X_train1.shape)\n",
    "print(X_train1.head())\n",
    "print(X_train2.shape)\n",
    "print(X_train2.head())\n",
    "combined1=pd.concat([X_train1, X_train2], axis=1)\n",
    "print(combined1.shape)\n",
    "print(combined1.head())\n",
    "export_csv= combined1.to_csv(r'/gdrive/My Drive/CIS508-FALL2020/PT5A/combined1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqwNFKiHLlbz",
    "outputId": "b1f25f4a-df46-4006-a96f-36caab38a2ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.958454\n",
      "Confusion Matrix:\n",
      "[[ 763   41]\n",
      " [  45 1221]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       0.94      0.95      0.95       804\n",
      "     Current       0.97      0.96      0.97      1266\n",
      "\n",
      "    accuracy                           0.96      2070\n",
      "   macro avg       0.96      0.96      0.96      2070\n",
      "weighted avg       0.96      0.96      0.96      2070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Construct a Random Forest Classifier WITHOUT text data\n",
    "\n",
    "rf_NT=clf.fit(combined1,y_train)\n",
    "print(\"Accuracy score (training): {0:.6f}\".format(rf_NT.score(combined1, y_train)))\n",
    "rf_predictions = rf_NT.predict(combined1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, rf_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_train, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MWgcUkWh0cI",
    "outputId": "0c3c02e8-7710-4026-9f66-917dc3d0f7d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== All Accuracy Scores ===\n",
      "[0.84436702 0.86391792 0.89508324 0.89934185 0.8953125  0.921875\n",
      " 0.8765625  0.821875   0.8796875  0.89375    0.90575397 0.90119048\n",
      " 0.93075397 0.7968254  0.90575397 0.87281746 0.91031746 0.93075397\n",
      " 0.88988095 0.91031746]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - WITHOUT Text:  0.8873068803232677\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run cross-validation - WITHOUT Text Data\n",
    "rf_NT_cv_score = cross_val_score(rf_NT, combined1, y_train, cv=20, scoring=\"balanced_accuracy\")\n",
    "print(\"=== All Accuracy Scores ===\")\n",
    "print(rf_NT_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean Accuracy Score ===\")\n",
    "print(\"Mean Accuracy Score - WITHOUT Text: \",rf_NT_cv_score.mean())\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ry-uqdi6DZZm"
   },
   "outputs": [],
   "source": [
    "#Customer Info One-Hot Encoded\n",
    "DF_Combined1= pd.DataFrame(combined1)\n",
    "export_csv= DF_Combined1.to_csv(r'/gdrive/My Drive/CIS508-FALL2020/PT5A/CustInfo_Onehot_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7xNgybX8Khh",
    "outputId": "e7dba8c8-8c0c-4ce3-caf1-3ceda3ba0f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12959207 0.14691575 0.04081563 0.11219452 0.08939292 0.12526403\n",
      " 0.02958592 0.08098107 0.00471494 0.02397168 0.02622187 0.\n",
      " 0.0081279  0.08175721 0.01034061 0.00209658 0.04699356 0.00510433\n",
      " 0.0144304  0.00712711 0.00553293 0.00578756 0.0030514 ]\n",
      "[ True  True False  True  True  True False  True False False False False\n",
      " False  True False False False False False False False False False]\n",
      "        0         1          2    3      4       5    6\n",
      "0     1.0  38000.00  24.393333  3.0  23.56  206.08  1.0\n",
      "1     2.0  29616.00  49.426667  2.0  29.78   45.50  0.0\n",
      "2     0.0  19732.80  50.673333  3.0  24.81   22.44  0.0\n",
      "3     2.0     96.33  56.473333  1.0  26.13   32.88  1.0\n",
      "4     2.0  52004.80  25.140000  1.0   5.03   23.11  0.0\n",
      "...   ...       ...        ...  ...    ...     ...  ...\n",
      "2065  0.0  78851.30  48.373333  4.0   0.37   28.66  1.0\n",
      "2066  1.0  17540.70  62.786667  1.0  22.17   13.45  1.0\n",
      "2067  0.0  83891.90  61.020000  4.0  28.92   45.47  0.0\n",
      "2068  2.0  28220.80  38.766667  4.0  26.49   12.46  0.0\n",
      "2069  0.0  28589.10  15.600000  3.0  13.19   87.09  1.0\n",
      "\n",
      "[2070 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#Do feature selection using a classification model\n",
    "#clf = ExtraTreesClassifier(n_estimators=50)\n",
    "#clf = GradientBoostingClassifier(n_estimators=50)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(DF_Combined1,y_train)\n",
    "print(clf.feature_importances_)\n",
    "#model = SelectFromModel(clf, prefit=True)\n",
    "model = SelectFromModel(clf, prefit=True, max_features=7, threshold=-np.inf)\n",
    "#model = SelectFromModel(clf, prefit=True)\n",
    "X_new= model.transform(DF_Combined1)\n",
    "X_new_SelectedFeatures= pd.DataFrame(X_new)\n",
    "export_csv= X_new_SelectedFeatures.to_csv(r'/gdrive/My Drive/CIS508-FALL2020/PT5A/X_new_SelectedFeatures.csv')\n",
    "\n",
    "print(model.get_support())\n",
    "print(X_new_SelectedFeatures)\n",
    "#print(X_new_SelectedFeatures.shape)\n",
    "#print(X_new_SelectedFeatures.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SMB33IG4yAgc",
    "outputId": "e77aa053-7ca8-429f-cf34-3178a90043b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: clodsa==1.2.43 in /usr/local/lib/python3.7/dist-packages (1.2.43)\n",
      "Requirement already satisfied: commentjson in /usr/local/lib/python3.7/dist-packages (from clodsa==1.2.43) (0.9.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from clodsa==1.2.43) (1.0.2)\n",
      "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (from clodsa==1.2.43) (0.5.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from clodsa==1.2.43) (1.21.6)\n",
      "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (from clodsa==1.2.43) (3.38.0)\n",
      "Requirement already satisfied: mahotas in /usr/local/lib/python3.7/dist-packages (from clodsa==1.2.43) (1.4.13)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from clodsa==1.2.43) (1.2.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from clodsa==1.2.43) (1.7.3)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from clodsa==1.2.43) (3.1.0)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from clodsa==1.2.43) (2.9.0)\n",
      "Requirement already satisfied: lark-parser<0.8.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from commentjson->clodsa==1.2.43) (0.7.8)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->clodsa==1.2.43) (1.5.2)\n",
      "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->clodsa==1.2.43) (3.3.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from progressbar2->clodsa==1.2.43) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->clodsa==1.2.43) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:    0.2s finished\n",
      "\n",
      "[2022-11-02 02:20:09] Features: 1/9 -- score: 0.8985507246376812[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.3s finished\n",
      "\n",
      "[2022-11-02 02:20:09] Features: 2/9 -- score: 0.9338164251207729[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    0.3s finished\n",
      "\n",
      "[2022-11-02 02:20:10] Features: 3/9 -- score: 0.9502415458937198[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.3s finished\n",
      "\n",
      "[2022-11-02 02:20:10] Features: 4/9 -- score: 0.9541062801932367[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    0.3s finished\n",
      "\n",
      "[2022-11-02 02:20:10] Features: 5/9 -- score: 0.9565217391304348[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    0.3s finished\n",
      "\n",
      "[2022-11-02 02:20:11] Features: 6/9 -- score: 0.9570048309178744[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    0.4s finished\n",
      "\n",
      "[2022-11-02 02:20:11] Features: 7/9 -- score: 0.957487922705314[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.3s finished\n",
      "\n",
      "[2022-11-02 02:20:11] Features: 8/9 -- score: 0.957487922705314[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.2s finished\n",
      "\n",
      "[2022-11-02 02:20:12] Features: 9/9 -- score: 0.957487922705314"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'feature_idx': (2,),\n",
       "  'cv_scores': array([0.89855072]),\n",
       "  'avg_score': 0.8985507246376812,\n",
       "  'feature_names': ('Usage',)},\n",
       " 2: {'feature_idx': (2, 4),\n",
       "  'cv_scores': array([0.93381643]),\n",
       "  'avg_score': 0.9338164251207729,\n",
       "  'feature_names': ('Usage', 'RatePlan')},\n",
       " 3: {'feature_idx': (2, 3, 4),\n",
       "  'cv_scores': array([0.95024155]),\n",
       "  'avg_score': 0.9502415458937198,\n",
       "  'feature_names': ('Usage', 'Age', 'RatePlan')},\n",
       " 4: {'feature_idx': (2, 3, 4, 5),\n",
       "  'cv_scores': array([0.95410628]),\n",
       "  'avg_score': 0.9541062801932367,\n",
       "  'feature_names': ('Usage', 'Age', 'RatePlan', 'LongDistance')},\n",
       " 5: {'feature_idx': (0, 2, 3, 4, 5),\n",
       "  'cv_scores': array([0.95652174]),\n",
       "  'avg_score': 0.9565217391304348,\n",
       "  'feature_names': ('Children', 'Usage', 'Age', 'RatePlan', 'LongDistance')},\n",
       " 6: {'feature_idx': (0, 1, 2, 3, 4, 5),\n",
       "  'cv_scores': array([0.95700483]),\n",
       "  'avg_score': 0.9570048309178744,\n",
       "  'feature_names': ('Children',\n",
       "   'Est_Income',\n",
       "   'Usage',\n",
       "   'Age',\n",
       "   'RatePlan',\n",
       "   'LongDistance')},\n",
       " 7: {'feature_idx': (0, 1, 2, 3, 4, 5, 17),\n",
       "  'cv_scores': array([0.95748792]),\n",
       "  'avg_score': 0.957487922705314,\n",
       "  'feature_names': ('Children',\n",
       "   'Est_Income',\n",
       "   'Usage',\n",
       "   'Age',\n",
       "   'RatePlan',\n",
       "   'LongDistance',\n",
       "   'Paymethod_CC')},\n",
       " 8: {'feature_idx': (0, 1, 2, 3, 4, 5, 6, 17),\n",
       "  'cv_scores': array([0.95748792]),\n",
       "  'avg_score': 0.957487922705314,\n",
       "  'feature_names': ('Children',\n",
       "   'Est_Income',\n",
       "   'Usage',\n",
       "   'Age',\n",
       "   'RatePlan',\n",
       "   'LongDistance',\n",
       "   'International',\n",
       "   'Paymethod_CC')},\n",
       " 9: {'feature_idx': (0, 1, 2, 3, 4, 5, 6, 7, 17),\n",
       "  'cv_scores': array([0.95748792]),\n",
       "  'avg_score': 0.957487922705314,\n",
       "  'feature_names': ('Children',\n",
       "   'Est_Income',\n",
       "   'Usage',\n",
       "   'Age',\n",
       "   'RatePlan',\n",
       "   'LongDistance',\n",
       "   'International',\n",
       "   'Local',\n",
       "   'Paymethod_CC')}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sequential Forward Search\n",
    "#from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "!pip install clodsa==1.2.43\n",
    "import joblib\n",
    "import sys\n",
    "sys.modules['sklearn.externals.joblib'] = joblib\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "sfs1 = SFS(clf, \n",
    "           k_features=9, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=0)\n",
    "\n",
    "sfs1 = sfs1.fit(DF_Combined1,y_train)\n",
    "sfs1.subsets_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gsMRXOuv0Fi9",
    "outputId": "bff3507a-658e-4134-82c7-798bbca3553f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Children', 'Est_Income', 'Usage', 'Age', 'RatePlan', 'LongDistance', 'International', 'Local', 'Paymethod_CC')\n",
      "0.957487922705314\n"
     ]
    }
   ],
   "source": [
    "#Sequential forward search result\n",
    "print(sfs1.k_feature_names_)\n",
    "print(sfs1.k_score_)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
